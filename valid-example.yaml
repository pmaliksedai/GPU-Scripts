---
apiVersion: resource.k8s.io/v1
kind: ResourceClaimTemplate
metadata:
  name: mig-devices
  namespace: gpu-test4
spec:
  spec:
    devices:
      requests:
        - name: mig-1g-5gb-0
          # v1: use 'exactly' / allocationMode + count + deviceClassName,
          # not deviceClassName/selectors at the top level
          exactly:
            deviceClassName: mig.nvidia.com
            allocationMode: ExactCount
            count: 1

---
# Deployment with multiple containers sharing GPU resources
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: gpu-test4
  name: gpu-workload
  labels:
    app: gpu-workload
spec:
  replicas: 2
  selector:
    matchLabels:
      app: gpu-workload
  template:
    metadata:
      labels:
        app: gpu-workload
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: sedai.nodepool.affinity
                    operator: In
                    values:
                      - gpu-pool-timesliced-mig-1g-5gb
      resourceClaims:
      - name: mig-devices
        resourceClaimTemplateName: mig-devices
      containers:
      - name: small-workload-1
        image: ubuntu:22.04
        command: ["bash", "-c"]
        args: ["nvidia-smi -L; trap 'exit 0' TERM; sleep 9999 & wait"]
        resources:
          claims:
          - name: mig-devices
            request: mig-1g-5gb-0
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
